{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import nltk\n",
    "import sklearn.metrics as skm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from more_itertools import locate\n",
    "from operator import itemgetter\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TMLXwWE0MMPB",
    "outputId": "d9a5bf1c-3bbc-4b86-aad8-76881952ed0c"
   },
   "outputs": [],
   "source": [
    "path = os.getcwd() + \"\\\\\"\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_MdzBbbLlo5k"
   },
   "source": [
    "#### **CODE TO SET UP FOR TRAINING AND CLASSIFICATION**\n",
    "##### **CHANGE THE CLASSIFICATION_LABEL TO BASS OR SAKE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_label = 'bass'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "31IqfyT8MU0Y"
   },
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "\n",
    "    # where we read in the training set\n",
    "    training_set_file = file_name\n",
    "\n",
    "    with open(path + training_set_file) as t:\n",
    "        training_set = t.readlines()\n",
    "\n",
    "    return training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "awkCx01PMXU4"
   },
   "outputs": [],
   "source": [
    "# remove punctuation and lowercase al\n",
    "def remove_punctuations(dataset):\n",
    "    processed_training_set = []\n",
    "    classA_count = 0\n",
    "    classB_count = 0\n",
    "\n",
    "    for i in dataset:\n",
    "        sentence_list = i.split(':')\n",
    "        sentence = ''.join(sentence_list[1:]).lower()\n",
    "        \n",
    "        # count the number of labels for each class\n",
    "        if sentence_list[0] == classification_label:\n",
    "            classA_count += 1\n",
    "        else:\n",
    "            classB_count += 1\n",
    "            \n",
    "        # remove the doc stuff\n",
    "        sentence = re.sub(r'\\<[\\W\\s]\\>', '', sentence)\n",
    "\n",
    "        # remove underscores and punctuation\n",
    "        sentence = re.sub(r'[^\\w\\s]', '', sentence).replace('_', '')\n",
    "\n",
    "        # remove starting spaces\n",
    "        sentence = re.sub(r'^\\s+', '', sentence)\n",
    "\n",
    "        sentence = sentence_list[0] + ':\\t' + sentence\n",
    "        processed_training_set.append(sentence.strip())\n",
    "\n",
    "    return processed_training_set, classA_count, classB_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGUzS7a2MZLw"
   },
   "outputs": [],
   "source": [
    "# increment count of a collocation according to it's belonging word class\n",
    "def increment_count(current_collocation, word_class, collocations):\n",
    "    if current_collocation not in collocations:\n",
    "    # if collocation is not present in collocations dictionary\n",
    "        count_in_class = {classification_label: 0, \"*\" + classification_label: 0}\n",
    "    else:\n",
    "        count_in_class = collocations[current_collocation]\n",
    "\n",
    "    # increment the count\n",
    "    count_in_class[word_class] += 1\n",
    "    \n",
    "    # store it in the dictionary\n",
    "    collocations[current_collocation] = count_in_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ugh1Q__uMait"
   },
   "outputs": [],
   "source": [
    "def collocations_in_positions(index, words_list, word_class, k, collocations):\n",
    "    for i in index:\n",
    "        # word at position i - k\n",
    "        if i - k > 0:\n",
    "            current_collocation = \" \".join(words_list[i - k: i + 1])\n",
    "            increment_count(current_collocation, word_class, collocations)\n",
    "\n",
    "        # word at position i + k\n",
    "        if i + k < len(words_list):\n",
    "            current_collocation = \" \".join(words_list[i: i + k + 1])\n",
    "            increment_count(current_collocation, word_class, collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "QUCD-1ekgAtg",
    "outputId": "82a26534-d714-4022-8349-08693b32be3b"
   },
   "outputs": [],
   "source": [
    "def pos_tagging(words_list):\n",
    "    # POS tag the words using nltk.pos_tag\n",
    "    return [pos[0] if pos[0] == classification_label else pos[1] for pos in nltk.pos_tag(words_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2hjr8NvkMcAa"
   },
   "outputs": [],
   "source": [
    "# to find the pos collocations\n",
    "def pos_collocations(index, words_list, word_class, k, collocations):\n",
    "    pos = pos_tagging(words_list)\n",
    "    for i in index:\n",
    "        # POS at i - k\n",
    "        if i - k > 0: \n",
    "            current_collocation = pos[i - k] + \" \" + ('* ' * (k - 1))  + words_list[i]\n",
    "            increment_count(current_collocation, word_class, collocations)\n",
    "\n",
    "        # POS at i + k\n",
    "        if i + k < len(words_list):\n",
    "            current_collocation = words_list[i] +  \" \" + ('* ' * (k - 1))  + pos[i + k]\n",
    "            increment_count(current_collocation, word_class, collocations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_collocations(words_list, word_class, collocations):\n",
    "    for word in words_list:\n",
    "        # don't count the word that is the classification label itself\n",
    "        if word != classification_label:\n",
    "            \n",
    "            # increment the count of other words found in +/- 10 words context\n",
    "            increment_count(word, word_class, collocations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "ETyN79HxMdm3",
    "outputId": "acd25cf5-04ff-4747-c401-4bb22553ec37"
   },
   "outputs": [],
   "source": [
    "def build_collocations(dataset):\n",
    "    collocations = {}\n",
    "    # build collocations\n",
    "    for line in dataset:\n",
    "        word_class, text = line.split(\":\\t\")\n",
    "        words_list = text.split()\n",
    "\n",
    "        # finding indexes of classification_word \n",
    "        index = list(locate(words_list, lambda a: a == classification_label))\n",
    "\n",
    "        # find words in position +/- 1\n",
    "        collocations_in_positions(index, words_list, word_class, 1, collocations)\n",
    "\n",
    "        # find words in position +/- 2\n",
    "        collocations_in_positions(index, words_list, word_class, 2, collocations)\n",
    "\n",
    "        # POS collocation in +/- 1 position\n",
    "        pos_collocations(index, words_list, word_class, 1, collocations)\n",
    "        \n",
    "        # Collocations in +/- 10 words context\n",
    "        window_collocations(words_list, word_class, collocations)\n",
    "    \n",
    "    return collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UAqdJREMfIA"
   },
   "outputs": [],
   "source": [
    "# error term as suggested in the paper\n",
    "error_term = .1\n",
    "def log_likelihood(collocation, count):\n",
    "    # if the sum of count of labels for a collocation is less than 2, then don't consider those collocations\n",
    "    if count[classification_label] + count['*' + classification_label] < 2:\n",
    "        return 0\n",
    "\n",
    "    # To add smoothing to our log-likelihood value\n",
    "    count_value1 = count[classification_label] + error_term\n",
    "    count_value2 = count['*' + classification_label] + error_term\n",
    "    \n",
    "    # get the count of each class label for a collocation and then calculate the log-likelihood\n",
    "    log_value = math.log2(count_value1 / count_value2)\n",
    "\n",
    "    return log_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "KQ2pcOMGMgZe",
    "outputId": "302b29c6-f0bd-426d-e134-f6aad3e37475"
   },
   "outputs": [],
   "source": [
    "# builds a decision list to use to categorize the data\n",
    "def build_decision_list(current_collocation):\n",
    "    decision_list = []\n",
    "    # for each collocation, calcuate the log-likelihood\n",
    "    for collocation, count in current_collocation.items():\n",
    "        log_value = log_likelihood(collocation, count)\n",
    "        \n",
    "        # if the log-likelihood value is less than 2, don't add it to the decision list\n",
    "        # since that collocation won't give us much information of the class label\n",
    "        if abs(log_value) < 2: continue\n",
    "        label = None\n",
    "        \n",
    "        # if the log_value is positive, then classify the collocation as classification_label\n",
    "        # and if it is negative then it is the other class label\n",
    "        if log_value > 0:\n",
    "            label = classification_label\n",
    "        else:\n",
    "            label = '*' + classification_label\n",
    "        decision_list.append((collocation, abs(log_value), label))\n",
    "\n",
    "    return decision_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    \n",
    "    # train the model for prediction\n",
    "    training_set = read_file(classification_label + '.trn')\n",
    "    # pre-process the dataset\n",
    "    processed_training_set, classA_count, classB_count = remove_punctuations(training_set)\n",
    "    \n",
    "    # assign a default class with respect to the majority count\n",
    "    default_class = classification_label if classA_count > classB_count else '*' + classification_label\n",
    "    \n",
    "    # build the collocation dictionary\n",
    "    collocations = build_collocations(processed_training_set)\n",
    "    \n",
    "    # sort the decision list so we can iterate with the highest probability first\n",
    "    decision_list = build_decision_list(collocations)\n",
    "    decision_list.sort(key=itemgetter(1), reverse=True)\n",
    "    \n",
    "    return decision_list, default_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "At3KtFI1Mh23"
   },
   "source": [
    "Classification Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sNIhjibDMnAS"
   },
   "outputs": [],
   "source": [
    "# test the sentence and find the rule\n",
    "def test_sentence(sentence, decision_list, default_class):\n",
    "    pos = pos_tagging(sentence.split())\n",
    "    for rules in decision_list: \n",
    "        \n",
    "        # if the current decision rule is found in the test sentence then return that decision rule\n",
    "        if ' ' + rules[0] + ' ' in sentence or rules[0] in pos:\n",
    "            return rules[2]\n",
    "\n",
    "    # return the class with majority count if nothing is in the decision tree that matches\n",
    "    return default_class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rne20H_XGxfg"
   },
   "outputs": [],
   "source": [
    "def statistics(actual_list, predicted_list):\n",
    "    #Confusion Metrics\n",
    "    print(\"Confusion Metrics: \")\n",
    "    print(skm.confusion_matrix(actual_list, predicted_list))\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    #Accuracy score\n",
    "    print(\"Accuracy Score \", (skm.accuracy_score(actual_list, predicted_list)) * 100, '%')\n",
    "    #Recall score\n",
    "    print(\"Recall Score \", skm.recall_score(actual_list, predicted_list, average=None))\n",
    "    #Precision score\n",
    "    print(\"Precision Score \", skm.precision_score(actual_list, predicted_list, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9KNzLliEMohO"
   },
   "outputs": [],
   "source": [
    "def test_model(decision_list, testing_set, default_class, flag=False):\n",
    "    count = 0\n",
    "    actual_list = []\n",
    "    predicted_list = []\n",
    "\n",
    "    # this is the whole test\n",
    "    for test in testing_set:\n",
    "        label, text = test.split(\":\\t\")\n",
    "        \n",
    "        # use model for classification\n",
    "        predicted_label = test_sentence(text, decision_list, default_class)\n",
    "\n",
    "        actual_list.append(label)\n",
    "        predicted_list.append(predicted_label)\n",
    "\n",
    "#         if flag:\n",
    "#             print(\"Predicted label %s vs Actual label %s \" % (predicted_label, label))\n",
    "\n",
    "        # how many we got wrong with our test\n",
    "        if predicted_label != label:\n",
    "            count += 1\n",
    "\n",
    "    return count, actual_list, predicted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "colab_type": "code",
    "id": "N05NOEdKMkKp",
    "outputId": "41231998-73f4-4510-95a0-c6e7811ab99f"
   },
   "outputs": [],
   "source": [
    "def testing(decision_list, default_class):\n",
    "    testing_set = read_file(classification_label + '.tst')\n",
    "    processed_testing_set = remove_punctuations(testing_set)[0]\n",
    "\n",
    "    # test the model\n",
    "    incorrect_count, actual_list, predicted_list = test_model(decision_list, processed_testing_set, default_class, True)\n",
    "\n",
    "    print(\"Number of incorrect classifications \", incorrect_count)\n",
    "\n",
    "    statistics(actual_list, predicted_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_list, default_class = train_model()\n",
    "testing(dec_list, default_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
